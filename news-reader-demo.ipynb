{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dff7b21f-b2cf-49db-95eb-1f6de1241b59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebb08a2a-3623-4dc2-a38a-46d4ecd88bed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = \"https://www.philstar.com/business/technology/2023/08/07/2286889/musk-says-his-cage-fight-zuckerberg-will-stream-x\"\n",
    "req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "html = urlopen(req).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c3e3810-74f1-410d-9d75-b02b98fb3824",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Musk says his cage fight with Zuckerberg will stream on X | Philstar.com</title>\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(html, 'html')\n",
    "\n",
    "# Get the title\n",
    "title = soup.title\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5e23232-7241-449b-b7ca-e83a1c6c329a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the paragraphs\n",
    "paragraphs = soup.find_all(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c75e3284-3b9c-431c-9b7b-588f5db35aab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WASHINGTON, United States — Elon Musk said Sunday that a \"cage match\" he and Meta CEO Mark Zuckerberg have seemingly agreed to as a fund-raiser will be carried live on X, formerly known as Twitter, which he owns., \"Zuck v Musk fight will be live-streamed on X,\" Musk posted. \"All proceeds will go to charity for veterans.\", Zuckerberg soon hit back on Threads, the new app he launched last month in a direct challenge to what was then still called Twitter, saying he was ready., \"Shouldn't we use a more reliable platform that can actually raise money for charity?\" he added, in a dig at the wave of problems faced by Musk's platform since he took over last year., The two billionaire entrepreneurs, who in the past have occasionally jousted from afar, became direct competitors after Zuckerberg's Meta launched its Twitter-like Threads platform in early July, quickly drawing 120 million users, according to Quiver Quantitative., Musk then posted on X, \"I'm up for a cage match if he is lol,\" referring to a form of Mixed Martial Arts in which rival fighters employ a variety of techniques -- like wrestling or Brazilian jiu-jitsu -- while limited by few rules., Zuckerberg, a martial arts enthusiast who has taken part in jiu-jitsu competitions, responded to Musk's initial, seemingly humorous, challenge by replying on Instagram \"Send me location.\" , The exchange sparked a torrent of reactions on social media, as well as prompting a lively round of betting on the potential winner. , The 39-year-old Zuckerberg, with his fighting experience, emerged as the clear favorite despite the decided size advantage of Musk, who is 52., No date has been set for the fight, which -- if it does happen -- is expected to take place in Las Vegas., The two tech giants have clashed over the years on issues ranging from politics to artificial intelligence.  , But the arrival of Threads heightened the pressure on the already troubled Twitter, which Musk rebranded to X last month., Musk bought that social network for $44 billion before announcing massive layoffs and opening the platform up to conspiracy-minded posters, leading several advertisers to turn elsewhere., Philstar.com is one of the most vibrant, opinionated, discerning communities of readers on cyberspace. With your meaningful insights, help shape the stories that can shape the country. Sign up now!]\n"
     ]
    }
   ],
   "source": [
    "p = str(paragraphs)\n",
    "cleantext = BeautifulSoup(p, \"html\").get_text()\n",
    "print(cleantext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8486fe67-a8e0-4b1b-8927-d79a1ba2e3aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-YOUR_OPENAI_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e1540bf-4f3d-4e63-a98b-a749ac9aae5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/InstructorEmbedding/instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c716d785-aeae-4f46-bd15-31b8c9f82e64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#splitting the text into\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.create_documents([cleantext])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef03eef5-1cb9-490b-be4b-89b1d02291f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c10fe5ec-ccc9-4625-b815-c6c02ff2e4d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\", \n",
    "                                                      model_kwargs={\"device\": \"cpu\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2ac4adc-ae4c-4528-929a-5d5bbac9ae0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Embed and store the texts\n",
    "# Supplying a persist_directory will store the embeddings on disk\n",
    "persist_directory = 'db-news-musk-match'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ca13d5b-9d67-4a0c-bbfd-edb89769c0d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: db-news-musk-match\n"
     ]
    }
   ],
   "source": [
    "## Here is the nmew embeddings being used\n",
    "embedding = instructor_embeddings\n",
    "\n",
    "vectordb = Chroma.from_documents(documents=texts, \n",
    "                                 embedding=embedding,\n",
    "                                 persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58521fde-0683-483b-b6c3-ecaa55135f90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# persist the db to disk\n",
    "vectordb.persist()\n",
    "vectordb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4123e52b-397f-4a8f-9de7-aac00f7e621f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: db-news-musk-match\n"
     ]
    }
   ],
   "source": [
    "# Now we can load the persisted database from disk, and use it as normal. \n",
    "vectordb = Chroma(persist_directory=persist_directory, \n",
    "                  embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65133684-7bbd-4740-a3a2-00e54919e60c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chroma collection langchain contains fewer than 4 elements.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(docs) 3\n"
     ]
    }
   ],
   "source": [
    "retriever = vectordb.as_retriever()\n",
    "docs = retriever.get_relevant_documents(\"What are the usage requirements?\")\n",
    "print(\"len(docs)\", len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d2f0724-decc-4970-ab8c-f5980095e0d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specifying top k\n",
    "# See https://python.langchain.com/en/latest/modules/indexes/retrievers/examples/vectorstore-retriever.html\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3edabf13-a788-4be5-881b-d95883738a3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create the chain to answer questions \n",
    "# https://python.langchain.com/docs/modules/chains/document/stuff\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=OpenAI(), \n",
    "                                  chain_type=\"stuff\", \n",
    "                                  retriever=retriever, \n",
    "                                  return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84b0382c-6715-4cf6-a775-5110b28c531d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def wrap_text_preserve_newlines(text, width=110):\n",
    "    # Split the input text into lines based on newline characters\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    # Wrap each line individually\n",
    "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
    "\n",
    "    # Join the wrapped lines back together using newline characters\n",
    "    wrapped_text = '\\n'.join(wrapped_lines)\n",
    "\n",
    "    return wrapped_text\n",
    "\n",
    "def process_llm_response(llm_response):\n",
    "    print(wrap_text_preserve_newlines(llm_response['result']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd48cdd-2626-42ba-bc45-453d9920682f",
   "metadata": {},
   "source": [
    "# Q&A Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91e5a6c8-4454-446d-8d5d-86ea01296bf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Elon Musk will fight Mark Zuckerberg in a cage match.\n"
     ]
    }
   ],
   "source": [
    "# full example\n",
    "query = \"Who will Elon Musk fight in a cage match?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f4e9a54-76be-42ba-b3fb-b25c7bb966cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The match will be broadcast on X (formerly known as Twitter), which is owned by Elon Musk.\n"
     ]
    }
   ],
   "source": [
    "# full example\n",
    "query = \"Where will the match be broadcast?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ea0edb4-7fe5-4198-b420-ec8b8e6069af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No date has been set for the fight, so it is not known when it will happen.\n"
     ]
    }
   ],
   "source": [
    "# full example\n",
    "query = \"When will the match happen?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e365675a-03a0-434b-9372-3a558b342c3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " It is too hard to say who will win as no date has been set for the fight yet.\n"
     ]
    }
   ],
   "source": [
    "# full example\n",
    "query = \"Who do you think will win?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a12e4d-704d-41c8-9c46-40cf119716a2",
   "metadata": {},
   "source": [
    "# Credits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae52d43f-8659-440e-a5b3-04f9bd33b5fd",
   "metadata": {},
   "source": [
    "Script based on Sam Witteveen work: https://www.youtube.com/watch?v=cFCGUjc33aU\n",
    "Check out his YouTube Channel: https://www.youtube.com/@samwitteveenai"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
